{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"ModelEvaluation(36k).ipynb","provenance":[],"collapsed_sections":["I8v38ixhiRSg","BA3muJ5o9iXk","RrgfXIrebyQy","gl53kyJMojWu","9ICcfIX94Vxy","-m9Y9teeu0Cb"],"toc_visible":true},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5"}},"cells":[{"cell_type":"markdown","metadata":{"id":"t6rYqv8qo2FF"},"source":["# Resources and credit:\n","- Detectron2 docs: https://detectron2.readthedocs.io/en/latest/index.html\n","- Conceptual: https://medium.com/@hirotoschwert/digging-into-detectron-2-part-5-6e220d762f9\n","- https://jonathan-hui.medium.com/map-mean-average-precision-for-object-detection-45c121a31173"]},{"cell_type":"markdown","metadata":{"id":"I8v38ixhiRSg"},"source":["# Imports\n","*Standard from Detectron2's docs*"]},{"cell_type":"markdown","metadata":{"id":"WsEmOHCOUaP7"},"source":["*Restart after executing this cell*"]},{"cell_type":"code","metadata":{"id":"cUl7ey7AhmBk","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1615163806527,"user_tz":480,"elapsed":8561,"user":{"displayName":"Jake Edward Taylor","photoUrl":"","userId":"03706230206312910017"}},"outputId":"e73948e5-2ac3-4514-9cb7-f588c63f03f8"},"source":["# install dependencies: \n","!pip install pyyaml==5.1\n","import torch, torchvision\n","print(torch.__version__, torch.cuda.is_available())\n","!gcc --version\n","# opencv is pre-installed on colab\n","exit(0)"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Collecting pyyaml==5.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9f/2c/9417b5c774792634834e730932745bc09a7d36754ca00acf1ccd1ac2594d/PyYAML-5.1.tar.gz (274kB)\n","\r\u001b[K     |█▏                              | 10kB 22.1MB/s eta 0:00:01\r\u001b[K     |██▍                             | 20kB 29.0MB/s eta 0:00:01\r\u001b[K     |███▋                            | 30kB 23.7MB/s eta 0:00:01\r\u001b[K     |████▉                           | 40kB 27.2MB/s eta 0:00:01\r\u001b[K     |██████                          | 51kB 25.6MB/s eta 0:00:01\r\u001b[K     |███████▏                        | 61kB 27.9MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 71kB 18.6MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 81kB 19.5MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 92kB 18.6MB/s eta 0:00:01\r\u001b[K     |████████████                    | 102kB 18.6MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 112kB 18.6MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 122kB 18.6MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 133kB 18.6MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 143kB 18.6MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 153kB 18.6MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 163kB 18.6MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 174kB 18.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████▌          | 184kB 18.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 194kB 18.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 204kB 18.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 215kB 18.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 225kB 18.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 235kB 18.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 245kB 18.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 256kB 18.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 266kB 18.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 276kB 18.6MB/s \n","\u001b[?25hBuilding wheels for collected packages: pyyaml\n","  Building wheel for pyyaml (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pyyaml: filename=PyYAML-5.1-cp37-cp37m-linux_x86_64.whl size=44074 sha256=e6db9c1b60a93f3def32e4455394b72778d3d33aa33479ff55d2e9dd38416cef\n","  Stored in directory: /root/.cache/pip/wheels/ad/56/bc/1522f864feb2a358ea6f1a92b4798d69ac783a28e80567a18b\n","Successfully built pyyaml\n","Installing collected packages: pyyaml\n","  Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","Successfully installed pyyaml-5.1\n","1.7.1+cu101 True\n","gcc (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0\n","Copyright (C) 2017 Free Software Foundation, Inc.\n","This is free software; see the source for copying conditions.  There is NO\n","warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"MVWMUAL_UWK1"},"source":["*Restart after executing this cell*"]},{"cell_type":"code","metadata":{"id":"I-Yf2EOhhmhM","colab":{"base_uri":"https://localhost:8080/","height":0},"executionInfo":{"status":"ok","timestamp":1615163818617,"user_tz":480,"elapsed":20642,"user":{"displayName":"Jake Edward Taylor","photoUrl":"","userId":"03706230206312910017"}},"outputId":"ca5fd9fc-02ab-4c2b-995f-52154f88cb7b"},"source":["# install detectron2: (Colab has CUDA 10.1 + torch 1.7)\n","# See https://detectron2.readthedocs.io/tutorials/install.html for instructions\n","import torch\n","assert torch.__version__.startswith(\"1.7\")\n","!pip install detectron2 -f https://dl.fbaipublicfiles.com/detectron2/wheels/cu101/torch1.7/index.html\n","exit(0)  # After installation, you need to \"restart runtime\" in Colab. This line can also restart runtime"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Looking in links: https://dl.fbaipublicfiles.com/detectron2/wheels/cu101/torch1.7/index.html\n","Collecting detectron2\n","\u001b[?25l  Downloading https://dl.fbaipublicfiles.com/detectron2/wheels/cu101/torch1.7/detectron2-0.3%2Bcu101-cp37-cp37m-linux_x86_64.whl (6.8MB)\n","\u001b[K     |████████████████████████████████| 6.8MB 718kB/s \n","\u001b[?25hRequirement already satisfied: cloudpickle in /usr/local/lib/python3.7/dist-packages (from detectron2) (1.3.0)\n","Requirement already satisfied: pydot in /usr/local/lib/python3.7/dist-packages (from detectron2) (1.3.0)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from detectron2) (3.2.2)\n","Collecting fvcore>=0.1.2\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fe/14/92d72b1e5ff9566e1cb3c000b9c29dd1f87177eebec79b840d47da205db5/fvcore-0.1.3.post20210306.tar.gz (46kB)\n","\u001b[K     |████████████████████████████████| 51kB 7.4MB/s \n","\u001b[?25hRequirement already satisfied: tensorboard in /usr/local/lib/python3.7/dist-packages (from detectron2) (2.4.1)\n","Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from detectron2) (0.16.0)\n","Collecting Pillow>=7.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1f/6d/b719ae8e21660a6a962636896dc4b7d657ef451a3ab941516401846ac5cb/Pillow-8.1.2-cp37-cp37m-manylinux1_x86_64.whl (2.2MB)\n","\u001b[K     |████████████████████████████████| 2.2MB 26.1MB/s \n","\u001b[?25hRequirement already satisfied: termcolor>=1.1 in /usr/local/lib/python3.7/dist-packages (from detectron2) (1.1.0)\n","Requirement already satisfied: tqdm>4.29.0 in /usr/local/lib/python3.7/dist-packages (from detectron2) (4.41.1)\n","Requirement already satisfied: pycocotools>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from detectron2) (2.0.2)\n","Requirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from detectron2) (0.8.9)\n","Collecting yacs>=0.1.6\n","  Downloading https://files.pythonhosted.org/packages/38/4f/fe9a4d472aa867878ce3bb7efb16654c5d63672b86dc0e6e953a67018433/yacs-0.1.8-py3-none-any.whl\n","Requirement already satisfied: pyparsing>=2.1.4 in /usr/local/lib/python3.7/dist-packages (from pydot->detectron2) (2.4.7)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->detectron2) (0.10.0)\n","Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.7/dist-packages (from matplotlib->detectron2) (1.19.5)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->detectron2) (2.8.1)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->detectron2) (1.3.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from fvcore>=0.1.2->detectron2) (5.1)\n","Collecting iopath>=0.1.2\n","  Downloading https://files.pythonhosted.org/packages/07/e3/5d16bd5056730737e5d11deafb89e7e7435afa9c8bf8748f94019f1d2260/iopath-0.1.4.tar.gz\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2) (2.23.0)\n","Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2) (1.15.0)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2) (1.0.1)\n","Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2) (0.36.2)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2) (0.4.2)\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2) (54.0.0)\n","Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2) (1.27.0)\n","Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2) (0.10.0)\n","Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2) (1.32.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2) (3.3.4)\n","Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2) (3.12.4)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2) (1.8.0)\n","Requirement already satisfied: cython>=0.27.3 in /usr/local/lib/python3.7/dist-packages (from pycocotools>=2.0.2->detectron2) (0.29.22)\n","Collecting portalocker\n","  Downloading https://files.pythonhosted.org/packages/82/22/e684c9e2e59b561dbe36538852e81849122c666c423448e3a5c99362c228/portalocker-2.2.1-py2.py3-none-any.whl\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2) (2020.12.5)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard->detectron2) (1.3.0)\n","Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard->detectron2) (4.7.2)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard->detectron2) (4.2.1)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard->detectron2) (0.2.8)\n","Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard->detectron2) (3.7.0)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard->detectron2) (3.1.0)\n","Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.7/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3.6\"->google-auth<2,>=1.6.3->tensorboard->detectron2) (0.4.8)\n","Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard->detectron2) (3.7.4.3)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard->detectron2) (3.4.0)\n","Building wheels for collected packages: fvcore, iopath\n","  Building wheel for fvcore (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for fvcore: filename=fvcore-0.1.3.post20210306-cp37-none-any.whl size=57728 sha256=fd590831d214334b5d79592cea3b1b69eb690ffc8635701ab697db034892c7a7\n","  Stored in directory: /root/.cache/pip/wheels/26/3e/e3/65a5d883afb6617a61eba64e851b4d0e1f8653c9cff34dc8f3\n","  Building wheel for iopath (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for iopath: filename=iopath-0.1.4-cp37-none-any.whl size=15571 sha256=f016da2b97d7e2d9cc07ad66397f17c624096c017648d3b62329a10e5d766e9a\n","  Stored in directory: /root/.cache/pip/wheels/54/3b/fb/25b60ef5989e3f5fd76fdc575c922e6e59066ddbd1b44756a9\n","Successfully built fvcore iopath\n","\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n","Installing collected packages: yacs, Pillow, portalocker, iopath, fvcore, detectron2\n","  Found existing installation: Pillow 7.0.0\n","    Uninstalling Pillow-7.0.0:\n","      Successfully uninstalled Pillow-7.0.0\n","Successfully installed Pillow-8.1.2 detectron2-0.3+cu101 fvcore-0.1.3.post20210306 iopath-0.1.4 portalocker-2.2.1 yacs-0.1.8\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["PIL"]}}},"metadata":{"tags":[]}}]},{"cell_type":"markdown","metadata":{"id":"eJhzFFwgY_hV"},"source":["# Registration\n","*Register train, test, test_offshore, test_inshore datasets*"]},{"cell_type":"code","metadata":{"id":"b6QvnlDKhc12","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1615163823896,"user_tz":480,"elapsed":1643,"user":{"displayName":"Jake Edward Taylor","photoUrl":"","userId":"03706230206312910017"}},"outputId":"81b736b9-4df3-4142-ecf5-69e9e2e1faf9"},"source":["# Some basic setup:\n","# Setup detectron2 logger\n","import detectron2\n","from detectron2.utils.logger import setup_logger\n","setup_logger()\n","\n","# import some common libraries\n","import numpy as np\n","import os, json, cv2, random\n","from google.colab.patches import cv2_imshow\n","\n","# import some common detectron2 utilities\n","from detectron2 import model_zoo\n","from detectron2.engine import DefaultPredictor\n","from detectron2.config import get_cfg\n","from detectron2.utils.visualizer import Visualizer\n","from detectron2.data import MetadataCatalog, DatasetCatalog\n","import matplotlib.pyplot as plt"],"execution_count":1,"outputs":[{"output_type":"stream","text":["** fvcore version of PathManager will be deprecated soon. **\n","** Please migrate to the version in iopath repo. **\n","https://github.com/facebookresearch/iopath \n","\n","** fvcore version of PathManager will be deprecated soon. **\n","** Please migrate to the version in iopath repo. **\n","https://github.com/facebookresearch/iopath \n","\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"9STMdFYLZEFt","executionInfo":{"status":"ok","timestamp":1615163838619,"user_tz":480,"elapsed":438,"user":{"displayName":"Jake Edward Taylor","photoUrl":"","userId":"03706230206312910017"}}},"source":["# Function that retrieves a standard dataset compatible with detectron2\n","def get_dict(type):\n","  \"\"\" Returns a list[dict] containing information about the dataset \"\"\"\n","  import pickle\n","  root = '/content/drive/MyDrive/SSDD/datasets/' + type + '/'\n","  with open(root + \"standardDict.pkl\", \"rb\") as input_file:\n","    return pickle.load(input_file)"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qZro5Wl0ZIXp","executionInfo":{"status":"ok","timestamp":1615163860671,"user_tz":480,"elapsed":17912,"user":{"displayName":"Jake Edward Taylor","photoUrl":"","userId":"03706230206312910017"}},"outputId":"9b50a11c-86c6-4261-bbb9-15ded97cdd4e"},"source":["# Global paths\n","datasets = '/content/drive/MyDrive/SSDD/datasets/'\n","# Mount drive\n","from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"aDzY5IiBZR33","executionInfo":{"status":"ok","timestamp":1615163862075,"user_tz":480,"elapsed":265,"user":{"displayName":"Jake Edward Taylor","photoUrl":"","userId":"03706230206312910017"}}},"source":["from detectron2.structures import BoxMode\n","# Register\n","for d in [\"train\", \"test\", \"test_offshore\", \"test_inshore\"]:\n","    DatasetCatalog.register(d, lambda d=d: get_dict(d))\n","    MetadataCatalog.get(d).set(thing_classes=[\"ship\"])"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"J2rQgRiSZiYl","executionInfo":{"status":"ok","timestamp":1615163867009,"user_tz":480,"elapsed":2644,"user":{"displayName":"Jake Edward Taylor","photoUrl":"","userId":"03706230206312910017"}}},"source":["# Instances of metadata\n","train_metadata = MetadataCatalog.get('train')\n","test_metadata = MetadataCatalog.get('test')\n","test_offshore = MetadataCatalog.get('test_offshore')\n","train_offshore = MetadataCatalog.get('train_offshore')"],"execution_count":5,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"BA3muJ5o9iXk"},"source":["# Model Loading"]},{"cell_type":"code","metadata":{"id":"WQxa302Gcp75"},"source":["# Quick copy/paste of models\n","# \"./ModelOutput/faster_rcnn_R_50_FPN_3x_1_23_2021_36000iters\"\n","#\"COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qlGfg0D6ejQu","executionInfo":{"status":"ok","timestamp":1615163999859,"user_tz":480,"elapsed":266,"user":{"displayName":"Jake Edward Taylor","photoUrl":"","userId":"03706230206312910017"}},"outputId":"d2db13c2-d62e-4422-e7aa-46048e231e9d"},"source":["% cd /content/drive/MyDrive/SSDD/\n","output = '/content/drive/MyDrive/SSDD/'\n","model_name = \"./ModelOutput/faster_rcnn_R_50_FPN_3x_1_23_2021_36000iters\" # Replace w/ folder"],"execution_count":7,"outputs":[{"output_type":"stream","text":["/content/drive/MyDrive/SSDD\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"U41kxQJc91Gz","executionInfo":{"status":"ok","timestamp":1615164001365,"user_tz":480,"elapsed":278,"user":{"displayName":"Jake Edward Taylor","photoUrl":"","userId":"03706230206312910017"}}},"source":["from detectron2.engine import DefaultTrainer\n","cfg = get_cfg()\n","cfg.merge_from_file(model_zoo.get_config_file(\"COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml\")) # Replace w/ config\n","cfg.DATASETS.TRAIN = (\"train\",)\n","cfg.DATASETS.TEST = ()\n","cfg.MODEL.ROI_HEADS.NUM_CLASSES = 1  # only has one class (ship)\n","cfg.OUTPUT_DIR = model_name\n","cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\") # Load custom weights\n","cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5 # pg.23 of Zhang et al.\n","cfg.MODEL.ROI_HEADS.NMS_THRESH_TEST  = 0.5 # pg.23 of Zhang et al."],"execution_count":8,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"RrgfXIrebyQy"},"source":["## Initialize Trainer\n","*Hidden for brevity*"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jbBqhuCN-GFL","executionInfo":{"status":"ok","timestamp":1615164062696,"user_tz":480,"elapsed":55091,"user":{"displayName":"Jake Edward Taylor","photoUrl":"","userId":"03706230206312910017"}},"outputId":"30c9e367-200c-4e85-b46d-2732e251c994"},"source":["trainer = DefaultTrainer(cfg)\n","trainer.resume_or_load(resume=True)"],"execution_count":9,"outputs":[{"output_type":"stream","text":["\u001b[32m[03/08 00:40:18 d2.engine.defaults]: \u001b[0mModel:\n","GeneralizedRCNN(\n","  (backbone): FPN(\n","    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n","    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n","    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n","    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n","    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (top_block): LastLevelMaxPool()\n","    (bottom_up): ResNet(\n","      (stem): BasicStem(\n","        (conv1): Conv2d(\n","          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n","          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n","        )\n","      )\n","      (res2): Sequential(\n","        (0): BottleneckBlock(\n","          (shortcut): Conv2d(\n","            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv1): Conv2d(\n","            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","        )\n","        (1): BottleneckBlock(\n","          (conv1): Conv2d(\n","            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","        )\n","        (2): BottleneckBlock(\n","          (conv1): Conv2d(\n","            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","        )\n","      )\n","      (res3): Sequential(\n","        (0): BottleneckBlock(\n","          (shortcut): Conv2d(\n","            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","          (conv1): Conv2d(\n","            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","        )\n","        (1): BottleneckBlock(\n","          (conv1): Conv2d(\n","            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","        )\n","        (2): BottleneckBlock(\n","          (conv1): Conv2d(\n","            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","        )\n","        (3): BottleneckBlock(\n","          (conv1): Conv2d(\n","            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","        )\n","      )\n","      (res4): Sequential(\n","        (0): BottleneckBlock(\n","          (shortcut): Conv2d(\n","            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","          (conv1): Conv2d(\n","            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (1): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (2): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (3): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (4): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (5): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","      )\n","      (res5): Sequential(\n","        (0): BottleneckBlock(\n","          (shortcut): Conv2d(\n","            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n","          )\n","          (conv1): Conv2d(\n","            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n","          )\n","        )\n","        (1): BottleneckBlock(\n","          (conv1): Conv2d(\n","            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n","          )\n","        )\n","        (2): BottleneckBlock(\n","          (conv1): Conv2d(\n","            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n","          )\n","        )\n","      )\n","    )\n","  )\n","  (proposal_generator): RPN(\n","    (rpn_head): StandardRPNHead(\n","      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n","      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n","    )\n","    (anchor_generator): DefaultAnchorGenerator(\n","      (cell_anchors): BufferList()\n","    )\n","  )\n","  (roi_heads): StandardROIHeads(\n","    (box_pooler): ROIPooler(\n","      (level_poolers): ModuleList(\n","        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n","        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n","        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n","        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n","      )\n","    )\n","    (box_head): FastRCNNConvFCHead(\n","      (flatten): Flatten(start_dim=1, end_dim=-1)\n","      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n","      (fc_relu1): ReLU()\n","      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n","      (fc_relu2): ReLU()\n","    )\n","    (box_predictor): FastRCNNOutputLayers(\n","      (cls_score): Linear(in_features=1024, out_features=2, bias=True)\n","      (bbox_pred): Linear(in_features=1024, out_features=4, bias=True)\n","    )\n","  )\n",")\n","\u001b[32m[03/08 00:40:54 d2.data.build]: \u001b[0mRemoved 4877 images with no usable annotations. 1123 images left.\n","\u001b[32m[03/08 00:40:54 d2.data.build]: \u001b[0mDistribution of instances among all 1 categories:\n","\u001b[36m|  category  | #instances   |\n","|:----------:|:-------------|\n","|    ship    | 3637         |\n","|            |              |\u001b[0m\n","\u001b[32m[03/08 00:40:54 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n","\u001b[32m[03/08 00:40:54 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n","\u001b[32m[03/08 00:40:54 d2.data.common]: \u001b[0mSerializing 1123 elements to byte tensors and concatenating them all ...\n","\u001b[32m[03/08 00:40:54 d2.data.common]: \u001b[0mSerialized dataset takes 0.34 MiB\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"mKoBbTRLu2sL"},"source":["# Evaluation"]},{"cell_type":"markdown","metadata":{"id":"E6IC3Lzkolun"},"source":["## Prediction"]},{"cell_type":"markdown","metadata":{"id":"_BBgMtWkUktb"},"source":["### Custom Evaluator"]},{"cell_type":"markdown","metadata":{"id":"v19MZg-KMCtf"},"source":["Follows: https://cs230.stanford.edu/section/7/"]},{"cell_type":"code","metadata":{"id":"O2cJS2zaD0sz","executionInfo":{"status":"ok","timestamp":1615164062697,"user_tz":480,"elapsed":22154,"user":{"displayName":"Jake Edward Taylor","photoUrl":"","userId":"03706230206312910017"}}},"source":["from detectron2.structures import Boxes, BoxMode, pairwise_iou\n","from detectron2.data.datasets.coco import convert_to_coco_json\n","from detectron2.evaluation import DatasetEvaluator\n","from detectron2.utils.file_io import PathManager\n","from collections import OrderedDict\n","from pycocotools.coco import COCO\n","import itertools\n","import contextlib\n","import torch\n","import copy\n","import os\n","import io"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"8axRZlJAfhff","executionInfo":{"status":"ok","timestamp":1615164062697,"user_tz":480,"elapsed":22143,"user":{"displayName":"Jake Edward Taylor","photoUrl":"","userId":"03706230206312910017"}}},"source":["def average_precision(correct, ground_truth): \n","  # correct contains True Positives (TP) and False Positives (FP)\n","  # ground_truth is the number of positive examples (TP + FN = GT)\n","\n","  # precision = TP / (TP + FP)\n","  # recall = TP / (TP + FN) = TP / GT\n","  TP = 0\n","  FP = 0\n","  GT = ground_truth\n","  precision = []\n","  recall = []\n","\n","  for i, c in enumerate(correct):\n","    if c:\n","      TP += 1\n","    else:\n","      FP += 1\n","    precision.append(TP / (TP + FP))\n","    if GT == 0:\n","      recall.append(0.0)\n","    else:\n","      recall.append(TP / GT)\n","\n","  # Interpolate precision (replace each precision value with the maximum\n","  # precision value to the right of that recall level)\n","  max = 0\n","  precision_interp = []\n","\n","  for i, c in enumerate(reversed(precision)):\n","    if c > max:\n","      max = c\n","      precision_interp.append(c)\n","    else:\n","      precision_interp.append(max)\n","  \n","  precision_interp = list(reversed(precision_interp))\n","\n","\n","  # Calculate AP (Average Precision)\n","  AP = 0\n","  for i, c in enumerate(recall):\n","    if i == 0:\n","      continue\n","    AP += (recall[i] - recall[i-1]) * precision_interp[i]\n","  \n","  return recall, precision_interp, AP\n","\n","\n","# Test Case\n","test = [True, True, False, False, False, True, True, False, False, True]\n","recall, precision, AP = average_precision(test, 5)\n","assert AP == 0.5285714285714286\n","assert recall == [0.2, 0.4, 0.4, 0.4, 0.4, 0.6, 0.8, 0.8, 0.8, 1.0]\n","assert precision == [1.0, \n","                    1.0, \n","                    0.6666666666666666,\n","                    0.5714285714285714,\n","                    0.5714285714285714,\n","                    0.5714285714285714,\n","                    0.5714285714285714,\n","                    0.5,\n","                    0.5,\n","                    0.5]"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"NANBaYNMtvHI","executionInfo":{"status":"ok","timestamp":1615164062996,"user_tz":480,"elapsed":22438,"user":{"displayName":"Jake Edward Taylor","photoUrl":"","userId":"03706230206312910017"}}},"source":["class CustomEvaluator(DatasetEvaluator):\n","  def __init__(\n","        self,\n","        dataset_name,\n","        output_dir\n","    ):\n","      \"\"\"\n","      Args:\n","          dataset_name (str): name of the dataset to be evaluated.\n","              It must have either the following corresponding metadata:\n","\n","                  \"json_file\": the path to the COCO format annotation\n","\n","              Or it must be in detectron2's standard dataset format\n","              so it can be converted to COCO format automatically.\n","          output_dir (str): an output directory to dump all\n","              results predicted on the dataset. The dump contains two files:\n","\n","              1. \"instances_predictions.pth\" (dataset_name + \"_predictions.pth\")\n","                  a file that can be loaded with `torch.load` and\n","                  contains all the results in the format they are produced by the model.\n","              2. \"coco_instances_results.json\" a json file in COCO's result format.\n","      \"\"\"\n","      self._cpu_device = torch.device(\"cpu\")\n","      self.dataset_name = dataset_name\n","      self._metadata = MetadataCatalog.get(dataset_name)\n","      self._output_dir = output_dir\n","      if not hasattr(self._metadata, \"json_file\"):\n","        cache_path = os.path.join(output_dir, f\"{dataset_name}_coco_format.json\")\n","        self._metadata.json_file = cache_path\n","        convert_to_coco_json(dataset_name, cache_path)\n","\n","      json_file = PathManager.get_local_path(self._metadata.json_file)\n","      with contextlib.redirect_stdout(io.StringIO()):\n","          self._coco_api = COCO(json_file)\n","\n","  def reset(self):\n","    \"\"\"\n","    Preparation for a new round of evaluation.\n","    \"\"\"\n","    self._predictions = []\n","\n","  def process(self, inputs, outputs):\n","    \"\"\"\n","    Process the pair of inputs and outputs.\n","    \"\"\"\n","    for input, output in zip(inputs, outputs):\n","      prediction = {\"image_id\": input[\"image_id\"]}\n","      if \"instances\" in output:\n","          prediction[\"instances\"] = output[\"instances\"].to(self._cpu_device) \n","      if len(prediction) > 1:\n","          self._predictions.append(prediction)\n","    if self._output_dir:\n","            PathManager.mkdirs(self._output_dir)\n","            file_path = os.path.join(self._output_dir,\n","                                     self.dataset_name + \"_predictions.pth\")\n","            with PathManager.open(file_path, \"wb\") as f:\n","                torch.save(self._predictions, f)\n","\n","  def evaluate(self):\n","    \"\"\"\n","    Evaluate/summarize the performance, after processing all input/output pairs.\n","    \"\"\"\n","    iou_threshold = 0.5 # pg.23 of Zhang et al. \n","    num_instances = 0\n","    num_pos = 0 # must be equal to GT\n","    gt_overlaps = []\n","    scores = []\n","    correct = []\n","    bad_images = []\n","\n","    if len(self._predictions) == 0:\n","      return {}, {}, {}\n","\n","    # Loop overall all instances in one image\n","    for prediction_dict in self._predictions:\n","      predictions = prediction_dict[\"instances\"]\n","      num_instances += len(predictions)\n","\n","      # Get scores of each instance, sort\n","      inds = predictions.get_fields()['scores'].sort(descending=True)[1]\n","      in_scores = predictions.get_fields()['scores']\n","      in_scores = in_scores[inds]\n","      \n","      # Get bbox of each instance, sort by score\n","      in_boxes = predictions.get_fields()['pred_boxes']\n","      in_boxes = in_boxes[inds]\n","\n","      assert len(in_boxes) == len(in_scores) == len(predictions)\n","\n","      # Retrieve corresponding ground truth boxes/labels\n","      ann_ids = self._coco_api.getAnnIds(imgIds=[prediction_dict[\"image_id\"]])\n","      anno = self._coco_api.loadAnns(ann_ids)\n","      gt_boxes = [\n","          BoxMode.convert(obj[\"bbox\"], BoxMode.XYWH_ABS, BoxMode.XYXY_ABS)\n","          for obj in anno\n","          if obj[\"iscrowd\"] == 0\n","      ]\n","      gt_boxes = torch.as_tensor(gt_boxes).reshape(-1, 4)\n","      gt_boxes = Boxes(gt_boxes)\n","\n","      num_pos += len(gt_boxes)\n","\n","      # Compute IOU for each instance-ground truth pair\n","      overlaps = pairwise_iou(in_boxes, gt_boxes)\n","\n","      _gt_overlaps = torch.zeros(len(gt_boxes)) # stores best pred/gt iou\n","      _scores = torch.zeros(len(in_scores)) # stores iou for each score\n","      \n","      # Ensure 1-1 mapping between prediction and gt boxes\n","      for j in range(min(len(predictions), len(gt_boxes))):\n","          # find which proposal box maximally covers each gt box\n","          # and get the iou amount of coverage for each gt box\n","          max_overlaps, argmax_overlaps = overlaps.max(dim=0)\n","\n","          # find which gt box is 'best' covered (i.e. 'best' = most iou)\n","          gt_ovr, gt_ind = max_overlaps.max(dim=0)\n","          assert gt_ovr >= 0\n","\n","          # find the proposal box that covers the best covered gt box\n","          box_ind = argmax_overlaps[gt_ind]\n","\n","          # record the iou coverage of this gt box\n","          _gt_overlaps[j] = overlaps[box_ind, gt_ind]\n","          assert _gt_overlaps[j] == gt_ovr\n","\n","          # record this iou coverage for score\n","          _scores[box_ind] =  overlaps[box_ind, gt_ind]\n","          assert _scores[box_ind] == gt_ovr\n","\n","          # mark the proposal box and the gt box as used\n","          overlaps[box_ind, :] = -1\n","          overlaps[:, gt_ind] = -1\n","\n","      # update collectors\n","      _correct = (_scores >= iou_threshold).tolist()\n","\n","      if _correct and sum(np.invert(_correct)) > 0:\n","        bad_images.append(prediction_dict)\n","      assert len(_correct) == len(_scores) == len(predictions)\n","      scores.append(in_scores)\n","      correct.append(_correct)\n","      gt_overlaps.append(_gt_overlaps)\n","\n","    gt_overlaps = (\n","        torch.cat(gt_overlaps, dim=0) if len(gt_overlaps)\n","         else torch.zeros(0, dtype=torch.float32)\n","    )\n","    gt_overlaps, _ = torch.sort(gt_overlaps, descending = True)\n","\n","    scores = (\n","        torch.cat(scores, dim=0) if len(scores)\n","         else torch.zeros(0, dtype=torch.float32)\n","    )\n","    scores, ind = torch.sort(scores, descending = True)\n","\n","    # stores TP/FP for each proposal box in all images \n","    # (in descending order of scores)\n","    correct = list(itertools.chain.from_iterable(correct))\n","    assert len(scores) == len(correct)\n","    correct = [correct[i] for i in ind.tolist()]\n","\n","    # The following metrics are computed at iou_threshold\n","    GT = len(self._coco_api.getAnnIds())\n","    assert GT == num_pos\n","\n","    TP = np.sum(np.array(correct))\n","    FP = len(correct) - TP\n","    assert (TP + FP) == num_instances\n","    FN = GT - TP\n","\n","    Pd = TP / GT          # Detection probability\n","    Pf = FP / (TP + FP)   # false alarm\n","    Pm = FN / GT          # missed detection\n","\n","    recall = TP / (TP + FN)\n","    precision = TP / (TP + FP)\n","    F1 = 2*(precision * recall) / (precision + recall)\n","    recalls, precisions, mAP = average_precision(correct, GT)\n","\n","    plot =  {\"recalls\": recalls, \"precisions\": precisions}\n","    hist = {\"gt_overlap\" : gt_overlaps, \"scores\": scores}\n","    self._results = {\n","        \"TP\": TP,\n","        \"FP\": FP,\n","        \"GT\": GT,\n","        \"FN\": FN,\n","        \"Pd\": Pd,\n","        \"Pf\": Pf,\n","        \"Pm\": Pm,\n","        \"recall\": recall,\n","        \"precision\": precision,\n","        \"mAP\": mAP,\n","        \"F1\": F1\n","    }\n","    return copy.deepcopy(self._results), plot, hist, bad_images"],"execution_count":12,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9ICcfIX94Vxy"},"source":["### Training Predictions"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HfUQGedw4Vx9","executionInfo":{"status":"ok","timestamp":1613025842797,"user_tz":480,"elapsed":474,"user":{"displayName":"Jake Edward Taylor","photoUrl":"","userId":"03706230206312910017"}},"outputId":"897383ba-7a5b-4415-fad3-0ef6a5d9c697"},"source":["from detectron2.evaluation import COCOEvaluator, DatasetEvaluators, inference_on_dataset\n","from detectron2.data import build_detection_test_loader\n","evaluator = COCOEvaluator('train', ('bbox',), False, output_dir=cfg.OUTPUT_DIR)\n","custEval = CustomEvaluator('train', output_dir=cfg.OUTPUT_DIR)\n","val_loader = build_detection_test_loader(cfg, 'train')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\u001b[32m[02/11 06:44:02 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n","\u001b[32m[02/11 06:44:02 d2.data.common]: \u001b[0mSerializing 6000 elements to byte tensors and concatenating them all ...\n","\u001b[32m[02/11 06:44:02 d2.data.common]: \u001b[0mSerialized dataset takes 1.01 MiB\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"xoibJLkZ4Vx-"},"source":["inference = inference_on_dataset(trainer.model,\n","                                 val_loader,\n","                                 custEval)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VmD_7bAI4Vx_"},"source":["# Alternatively, load predictions directly from file into custEval instance\n","#temp = custEval._predictions\n","temp = torch.load(os.path.join(cfg.OUTPUT_DIR, \"train_predictions.pth\"))\n","custEval._predictions = temp\n","# evaluator._predictions = temp\n","# evaluator.evaluate()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EHOFvGCv4Vx_","executionInfo":{"status":"ok","timestamp":1613025915804,"user_tz":480,"elapsed":3236,"user":{"displayName":"Jake Edward Taylor","photoUrl":"","userId":"03706230206312910017"}},"outputId":"e128974c-8614-4409-e55c-92258ba8e7a1"},"source":["eval, plot, hist, bad_images = custEval.evaluate()\n","eval"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'F1': 0.6187134502923975,\n"," 'FN': 1521,\n"," 'FP': 1087,\n"," 'GT': 3637,\n"," 'Pd': 0.5817981853175694,\n"," 'Pf': 0.33936934124258505,\n"," 'Pm': 0.41820181468243056,\n"," 'TP': 2116,\n"," 'mAP': 0.5232960410635557,\n"," 'precision': 0.6606306587574149,\n"," 'recall': 0.5817981853175694}"]},"metadata":{"tags":[]},"execution_count":74}]},{"cell_type":"code","metadata":{"id":"Cp_WeEgs4VyA"},"source":["# Precision Recall Curve\n","plt.plot(plot['recalls'], plot['precisions'])\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TJedN6Oy4VyA"},"source":["# Scores of when gt_overlaps when (len(gt_box) != 0)\n","plt.hist(hist['scores'])\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cwOmlC824VyA"},"source":["# iou values for all matching instances (no threshold)\n","plt.hist(hist['gt_overlap'])\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"h5RMNtMNUtoA"},"source":["### Test Predictions"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HYr4VgBmsQaK","executionInfo":{"status":"ok","timestamp":1615165885989,"user_tz":480,"elapsed":975,"user":{"displayName":"Jake Edward Taylor","photoUrl":"","userId":"03706230206312910017"}},"outputId":"885b818b-a6c7-4aaf-dd52-7a02de8ca5d8"},"source":["from detectron2.evaluation import COCOEvaluator, DatasetEvaluators, inference_on_dataset\n","from detectron2.data import build_detection_test_loader\n","evaluator = COCOEvaluator('test_inshore', ('bbox',), False, output_dir=cfg.OUTPUT_DIR)\n","custEval = CustomEvaluator('test_inshore', output_dir=cfg.OUTPUT_DIR)\n","val_loader = build_detection_test_loader(cfg, 'test_inshore')"],"execution_count":23,"outputs":[{"output_type":"stream","text":["\u001b[32m[03/08 01:11:25 d2.evaluation.coco_evaluation]: \u001b[0m'test_inshore' is not registered by `register_coco_instances`. Therefore trying to convert it to COCO format ...\n","\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[03/08 01:11:25 d2.data.datasets.coco]: \u001b[0mUsing previously cached COCO format annotations at './ModelOutput/faster_rcnn_R_50_FPN_3x_1_23_2021_36000iters/test_inshore_coco_format.json'. You need to clear the cache file if your dataset has been modified.\n","\u001b[32m[03/08 01:11:26 d2.data.build]: \u001b[0mDistribution of instances among all 1 categories:\n","\u001b[36m|  category  | #instances   |\n","|:----------:|:-------------|\n","|    ship    | 883          |\n","|            |              |\u001b[0m\n","\u001b[32m[03/08 01:11:26 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n","\u001b[32m[03/08 01:11:26 d2.data.common]: \u001b[0mSerializing 766 elements to byte tensors and concatenating them all ...\n","\u001b[32m[03/08 01:11:26 d2.data.common]: \u001b[0mSerialized dataset takes 0.14 MiB\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"VzC8U0AT4a0l","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1615165987861,"user_tz":480,"elapsed":100203,"user":{"displayName":"Jake Edward Taylor","photoUrl":"","userId":"03706230206312910017"}},"outputId":"fcdb5579-b043-448e-d14b-a847f8d1f519"},"source":["inference = inference_on_dataset(trainer.model,\n","                                 val_loader,\n","                                 custEval)"],"execution_count":24,"outputs":[{"output_type":"stream","text":["\u001b[32m[03/08 01:11:27 d2.evaluation.evaluator]: \u001b[0mStart inference on 766 images\n","\u001b[32m[03/08 01:11:29 d2.evaluation.evaluator]: \u001b[0mInference done 11/766. 0.0812 s / img. ETA=0:01:10\n","\u001b[32m[03/08 01:11:34 d2.evaluation.evaluator]: \u001b[0mInference done 66/766. 0.0753 s / img. ETA=0:01:04\n","\u001b[32m[03/08 01:11:39 d2.evaluation.evaluator]: \u001b[0mInference done 118/766. 0.0749 s / img. ETA=0:01:00\n","\u001b[32m[03/08 01:11:44 d2.evaluation.evaluator]: \u001b[0mInference done 167/766. 0.0749 s / img. ETA=0:00:57\n","\u001b[32m[03/08 01:11:49 d2.evaluation.evaluator]: \u001b[0mInference done 216/766. 0.0745 s / img. ETA=0:00:53\n","\u001b[32m[03/08 01:11:54 d2.evaluation.evaluator]: \u001b[0mInference done 261/766. 0.0743 s / img. ETA=0:00:50\n","\u001b[32m[03/08 01:11:59 d2.evaluation.evaluator]: \u001b[0mInference done 304/766. 0.0741 s / img. ETA=0:00:47\n","\u001b[32m[03/08 01:12:04 d2.evaluation.evaluator]: \u001b[0mInference done 346/766. 0.0739 s / img. ETA=0:00:44\n","\u001b[32m[03/08 01:12:09 d2.evaluation.evaluator]: \u001b[0mInference done 388/766. 0.0737 s / img. ETA=0:00:40\n","\u001b[32m[03/08 01:12:15 d2.evaluation.evaluator]: \u001b[0mInference done 429/766. 0.0737 s / img. ETA=0:00:36\n","\u001b[32m[03/08 01:12:20 d2.evaluation.evaluator]: \u001b[0mInference done 468/766. 0.0736 s / img. ETA=0:00:32\n","\u001b[32m[03/08 01:12:25 d2.evaluation.evaluator]: \u001b[0mInference done 505/766. 0.0736 s / img. ETA=0:00:29\n","\u001b[32m[03/08 01:12:30 d2.evaluation.evaluator]: \u001b[0mInference done 542/766. 0.0735 s / img. ETA=0:00:25\n","\u001b[32m[03/08 01:12:35 d2.evaluation.evaluator]: \u001b[0mInference done 565/766. 0.0735 s / img. ETA=0:00:23\n","\u001b[32m[03/08 01:12:40 d2.evaluation.evaluator]: \u001b[0mInference done 599/766. 0.0736 s / img. ETA=0:00:20\n","\u001b[32m[03/08 01:12:45 d2.evaluation.evaluator]: \u001b[0mInference done 632/766. 0.0736 s / img. ETA=0:00:16\n","\u001b[32m[03/08 01:12:51 d2.evaluation.evaluator]: \u001b[0mInference done 665/766. 0.0736 s / img. ETA=0:00:12\n","\u001b[32m[03/08 01:12:56 d2.evaluation.evaluator]: \u001b[0mInference done 697/766. 0.0735 s / img. ETA=0:00:08\n","\u001b[32m[03/08 01:13:01 d2.evaluation.evaluator]: \u001b[0mInference done 728/766. 0.0735 s / img. ETA=0:00:04\n","\u001b[32m[03/08 01:13:06 d2.evaluation.evaluator]: \u001b[0mInference done 759/766. 0.0735 s / img. ETA=0:00:00\n","\u001b[32m[03/08 01:13:07 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:01:38.555966 (0.129508 s / img per device, on 1 devices)\n","\u001b[32m[03/08 01:13:07 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:55 (0.073471 s / img per device, on 1 devices)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"wyMC9eQ3w_w_","executionInfo":{"status":"ok","timestamp":1615165861152,"user_tz":480,"elapsed":264,"user":{"displayName":"Jake Edward Taylor","photoUrl":"","userId":"03706230206312910017"}}},"source":["# Alternatively, load predictions directly from file into custEval instance\n","#temp = custEval._predictions\n","temp = torch.load(os.path.join(cfg.OUTPUT_DIR, \"test_inshore_predictions.pth\"))\n","custEval._predictions = temp\n","# evaluator._predictions = temp\n","# evaluator.evaluate()"],"execution_count":21,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"58NJfQyBTMrv","executionInfo":{"status":"ok","timestamp":1615166080815,"user_tz":480,"elapsed":579,"user":{"displayName":"Jake Edward Taylor","photoUrl":"","userId":"03706230206312910017"}},"outputId":"47131a24-1334-41e6-948f-8b6ff1049050"},"source":["eval, plot, hist, bad_images = custEval.evaluate()\n","eval"],"execution_count":25,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'F1': 0.5055762081784387,\n"," 'FN': 475,\n"," 'FP': 323,\n"," 'GT': 883,\n"," 'Pd': 0.46206115515288787,\n"," 'Pf': 0.4418604651162791,\n"," 'Pm': 0.5379388448471121,\n"," 'TP': 408,\n"," 'mAP': 0.3864668548203188,\n"," 'precision': 0.5581395348837209,\n"," 'recall': 0.46206115515288787}"]},"metadata":{"tags":[]},"execution_count":25}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":265},"id":"BEPeHX9ybaaO","executionInfo":{"status":"ok","timestamp":1613022972796,"user_tz":480,"elapsed":486,"user":{"displayName":"Jake Edward Taylor","photoUrl":"","userId":"03706230206312910017"}},"outputId":"c89d3844-54aa-4b59-be77-4592010a2ac3"},"source":["# Precision Recall Curve\n","plt.plot(plot['recalls'], plot['precisions'])\n","plt.show()"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":265},"id":"t-W6WR4mgdxU","executionInfo":{"status":"ok","timestamp":1613022974386,"user_tz":480,"elapsed":417,"user":{"displayName":"Jake Edward Taylor","photoUrl":"","userId":"03706230206312910017"}},"outputId":"790b8f39-e709-45fe-9432-02497ea8bca5"},"source":["# Scores of when gt_overlaps when (len(gt_box) != 0)\n","plt.hist(hist['scores'])\n","plt.show()"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":267},"id":"hsvmUNaYgkvr","executionInfo":{"status":"ok","timestamp":1613022976503,"user_tz":480,"elapsed":448,"user":{"displayName":"Jake Edward Taylor","photoUrl":"","userId":"03706230206312910017"}},"outputId":"68dda38c-d1b2-4796-bf02-1dd2314049c6"},"source":["# iou values for all matching instances (no threshold)\n","plt.hist(hist['gt_overlap'])\n","plt.show()"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"markdown","metadata":{"id":"-m9Y9teeu0Cb"},"source":["### Visualization"]},{"cell_type":"code","metadata":{"id":"uf87wjcy_MkI"},"source":["predictor = DefaultPredictor(cfg)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Xpk62sgKYJWp"},"source":["dataset_dicts = get_dict(\"train\")\n","bad_images_ind = [i['image_id'] for i in bad_images]\n","# Filter out pics w/o annotations\n","dataset_dicts_anns = []\n","for i in dataset_dicts:\n","  if i['image_id'] in bad_images_ind:\n","    dataset_dicts_anns.append(i)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PdQLPqmqXyni"},"source":["def printImage(ann, metadata, predictor = None, predFlag = False):\n","  from detectron2.utils.visualizer import Visualizer\n","  im = cv2.imread(ann[\"file_name\"])\n","  v = Visualizer(im[:, :, ::-1], \n","                 metadata=metadata, \n","                 scale=0.5)\n","  if predFlag:\n","    outputs = predictor(im)  \n","    out = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n","  else:\n","    out = v.draw_dataset_dict(ann)\n","  image = out.get_image()[:, :, ::-1]\n","  return image"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"uoNgFyB0Z1zB"},"source":["from cv2 import hconcat\n","num_samples = 364\n","os.makedirs(model_name + \"/predImages\", exist_ok=True) # Make a directory for output images\n","#random.seed(1)\n","for d in random.sample(dataset_dicts_anns, num_samples):\n","  image1 = printImage(d, test_metadata, predictor, True) # Predictions\n","  image2 = printImage(d, test_metadata, False) # Ground truth\n","  image3 = hconcat([image1, image2])\n","  #cv2_imshow(image3)\n","  cv2.imwrite(model_name + '/predImages/' + str(d[\"image_id\"] + '.jpg'), image3)"],"execution_count":null,"outputs":[]}]}